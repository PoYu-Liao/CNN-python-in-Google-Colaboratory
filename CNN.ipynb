{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catcodecpe/CNN-python-in-Google-Colaboratory/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxDznp_zAEyX"
      },
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "\n",
        "\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "\n",
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p MyDrive\n",
        "!google-drive-ocamlfuse MyDrive\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1SlMLkHy5iQ"
      },
      "source": [
        "#version\n",
        "cat /etc/os-release"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9HYbak92Es4"
      },
      "source": [
        "#cpu\n",
        "!lscpu |grep 'Model name'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WquerQFEdzQA"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syilk8JId7bX"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90sWxB4Gd-Fj"
      },
      "source": [
        "#memory that we can use\n",
        "!cat /proc/meminfo | grep 'MemAvailable'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y92GHnLzBViK"
      },
      "source": [
        "!ls MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH1Gvvqo-piZ"
      },
      "source": [
        "!ls MyDrive/\"Colab Notebooks\"/\"CNN\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euMf2pn7wPCV"
      },
      "source": [
        "#install tensorflow Data Validation\n",
        "#pip download tensorflow_data_validation \\\n",
        "#--no-deps \\\n",
        "#--platform manylinux1_x86_64 \\\n",
        "#--only-binary=:all:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ghYgAx5zqB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPq57ebw5z2M"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow_data_validation as tfdv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwVq3WTz565Z"
      },
      "source": [
        "data = {}\n",
        "\n",
        "def resize(image, tw=150, th=150):\n",
        "    w, h =np.shape(image)\n",
        "    \n",
        "    if w>150 and h>150:\n",
        "        dw = int((w - tw)/2)\n",
        "        dh = int((h - th)/2)\n",
        "        image = image[dw:-dw, dh:-dh]\n",
        "    image =cv2.resize(image, (tw, th))\n",
        "    return image[:, :, np.newaxis]\n",
        "\n",
        "\n",
        "def load(dir_name):\n",
        "    tmp=[]\n",
        "    filenames = []\n",
        "    for file in os.listdir(dir_name):\n",
        "        filename = \"{}/{}\".format(dir_name, file)\n",
        "        image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "        image = resize(image)\n",
        "        tmp.append(image)\n",
        "        filenames.append(file)\n",
        "    return tmp,  filenames\n",
        "\n",
        "data[\"cat\"],_ = load(\"./MyDrive/Colab Notebooks/CNN/training/cat\")\n",
        "data[\"dog\"],_ = load(\"./MyDrive/Colab Notebooks/CNN/training/dog\")\n",
        "data[\"horse\"],_ = load(\"./MyDrive/Colab Notebooks/CNN/training/horse\")\n",
        "data[\"chicken\"],_ = load(\"./MyDrive/Colab Notebooks/CNN/training/chicken\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NugcA7kq58Ng"
      },
      "source": [
        "image_width = 150\n",
        "image_height = 150\n",
        "image_depth = 1\n",
        "\n",
        "vocab_size = 4\n",
        "\n",
        "types = {\n",
        "    \"cat\": 0,\n",
        "    \"dog\": 1,\n",
        "    \"horse\": 2,\n",
        "    \"chicken\": 3\n",
        "    \n",
        "    \n",
        "    \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEpsVpS_6C3Z"
      },
      "source": [
        "train_input = tf.placeholder(tf.float32, (None, image_height, image_width, image_depth), \"train_input\")\n",
        "train_label = tf.placeholder(tf.int32, (None,), \"train_label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQcTfJ2j6Gy4"
      },
      "source": [
        "def part(tag, under, upper):\n",
        "    L = len(data[tag])\n",
        "    a = i%L\n",
        "    b = (i+2)%L\n",
        "    if b > a:\n",
        "        v = np.array(data[tag][a:b])\n",
        "    elif b==0:\n",
        "        v = np.array(data[tag][a:])\n",
        "    else:\n",
        "        v1 = np.array(data[tag][a:])\n",
        "        v2 = np.array(data[tag][:b])\n",
        "        v = np.concatenate((v1, v2), 0)\n",
        "    return v\n",
        "\n",
        "def feed(i):\n",
        "    X = part(\"cat\", i, i+2)\n",
        "    X = np.concatenate((X, part(\"dog\", i, i+2)), 0)\n",
        "    X = np.concatenate((X, part(\"horse\", i, i+2)), 0)\n",
        "    X = np.concatenate((X, part(\"chicken\", i, i+2)), 0)\n",
        "    Y = np.array([0, 0, 1, 1, 2, 2, 3, 3])\n",
        "    return {\n",
        "        train_input: X,\n",
        "        train_label: Y\n",
        "    \n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgRK12nt6JX-"
      },
      "source": [
        "#convolution 1\n",
        "conv1 = tf.layers.conv2d(inputs = train_input, filters=8, kernel_size=[50, 50], padding=\"same\")\n",
        "pool1 = tf.layers.max_pooling2d(inputs = conv1, pool_size=[2, 2], strides=2)\n",
        "\n",
        "#convolution 2\n",
        "conv2 = tf.layers.conv2d(inputs = conv1, filters=32, kernel_size=[35, 35], padding=\"same\")\n",
        "pool2 = tf.layers.max_pooling2d(inputs = conv2, pool_size=[2, 2], strides=1)\n",
        "\n",
        "\n",
        "#convolution 3\n",
        "conv3 = tf.layers.conv2d(inputs = conv2, filters=32, kernel_size=[25, 25], padding=\"same\")\n",
        "pool3 = tf.layers.max_pooling2d(inputs = conv3, pool_size=[3, 3], strides=3)\n",
        "\n",
        "\n",
        "#convolution 4\n",
        "conv4 = tf.layers.conv2d(inputs = pool3, filters=64, kernel_size=[10, 10], padding=\"same\")\n",
        "pool4 = tf.layers.max_pooling2d(inputs = conv4, pool_size=[2, 2], strides=2)\n",
        "\n",
        "#convolution 5\n",
        "conv5 = tf.layers.conv2d(inputs = pool4, filters=128, kernel_size=[5, 5], padding=\"same\")\n",
        "pool5 = tf.layers.max_pooling2d(inputs = conv5, pool_size=[5, 5], strides=5)\n",
        "\n",
        "\n",
        "\n",
        "#Flatten\n",
        "flat = tf.contrib.layers.flatten(pool5)\n",
        "\n",
        "#fully Connected\n",
        "output = tf.contrib.layers.fully_connected(flat, vocab_size, activation_fn=None)\n",
        "#print(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrYCGLak6hNw"
      },
      "source": [
        "#Prediction\n",
        "prediction_rate =tf.nn.softmax(output)\n",
        "prediction_result = tf.argmax(prediction_rate, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlFBY-h66lBg"
      },
      "source": [
        "#Cost\n",
        "target = tf.one_hot(train_label, depth=vocab_size, dtype=tf.float32)\n",
        "loss_function = tf.nn.softmax_cross_entropy_with_logits_v2(labels=target, logits=output)\n",
        "loss = tf.reduce_mean(loss_function)\n",
        "\n",
        "\n",
        "#Optimizer\n",
        "optimizer = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT5cW8iJ6np2"
      },
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h69Ok3V56qHT"
      },
      "source": [
        "vs =[]\n",
        "t = []\n",
        "\n",
        "\n",
        "for i in range(0, 850):\n",
        "    fd = feed(i)\n",
        "    _, v = sess.run([optimizer, loss], fd)\n",
        "    print(\"time: {}, loss: {}\".format(i, v))\n",
        "    vs.append(v) \n",
        "    t.append(i)\n",
        "\n",
        "#750 800 850 900 950"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZkOk-ih6rDD"
      },
      "source": [
        "#loss curve\n",
        "plt.plot(t, vs)\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2IQ6lBe74EO"
      },
      "source": [
        "#Test\n",
        "test_data, files = load(\"./MyDrive/Colab Notebooks/CNN/test\")\n",
        "\n",
        "result = sess.run(prediction_rate, { train_input: test_data})\n",
        "for i in range(0, 8):\n",
        "    r = np.round(result[i]*100, 2)\n",
        "    print(\"filename: {}\\t cat:{}%, dog:{}%, horse:{}%, chicken:{}%\".format(files[i], r[0], r[1], r[2], r[3]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}